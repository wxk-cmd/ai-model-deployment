# 模型端

## 模型参数获取文件 get_config.py

这个文件在main.py中进行引用，主要是为了更新最新的模型配置文件。

下面代码是get_config.py中的获更新模型配置文件的主要函数get_model_config

```
def get_model_config(model_url):			#主要用来更新配置文件的函数
    response = requests.get(model_url)
    python_code=f"model_config={json.dumps(response.json(),indent=4)}"
    print(python_code)
    with open('model_config.py',"w") as py_file:
        py_file.write(python_code)
       
```

下面代码是main.py中进行调用，需要将model_url改为相应的api地址，这个首先会通过api去获取最新的配置文件，通过上方的函数去更新配置文件，最后再去获取配置文件去做推理。

```
model_url= "192.168.0.203"
get_config.get_model_config(model_url)
yolo_model_configs = model_config.modelconfig
```



## 模型配置文件：model_config.py

```
yolo_model_configs = {
    "phone": {  #模型名称
        "weights": "Model/phone_best.pt",  #模型的权重文件路径
        "img_size": 416,  #输入图像的尺寸
        "conf_thres": 0.7,  #置信度阈值
        "event": "phone"  #检测的事件类型
    },
    "safetyhat": {
        "weights": "Model/safety_hemlt.pt",
        "img_size": 640,
        "conf_thres": 0.7,
        "event": "head" 
    },
    "smoking": {
        "weights": "Model/smoking.pt",
        "img_size": 416,
        "conf_thres": 0.5,
        "event": "smoking" 
    },
    "face": {
        "weights": "Model/face_best.pt",
        "img_size": 640,
        "conf_thres": 0.25,
        "event": "face"
    }
}
```



# 摄像头端



## 摄像头参数获取文件 get_config.py

这个文件也是在main.py中进行引用，主要是为了更新最新的摄像头配置文件。

下面代码是get_config.py中的获更新模型配置文件的主要函数get_camera_config

```
def get_camera_config(url):
    response = requests.get(url)
    print(response.json())
    python_code=f"camera_config={json.dumps(response.json(),indent=4)}"
    with open('camera_config.py',"w") as py_file:
        py_file.write(python_code)
```

下面代码是main.py中进行调用，需要将camera_url改为相应的api地址，这个首先会通过api去获取最新的配置文件，通过上方的函数去更新配置文件，最后再去获取配置文件去做推理。

    camera_url = "http://192.168.0.203:8000/api/allEquipments"
    get_config.get_camera_config(camera_url)  #up
    camera_configs=camera_config.camera_config

## 摄像头配置文件 camera_config.py

这里如果没有face_path,就不要写成空，就不要在里面添加face的配置文件，因为没有在主函数里面写入相关的语句（后期会加）

```
camera_configs = {
    "1": {  # "1"是摄像头id
        "camera_name": "1",
        “angle": 0,  #摄像头的角度信息
        "url": "rtsp://admin:wspw123456@192.168.0.10/Streaming/Channels/1",  #摄像头的RTSP流的URL地址
        "models": {
            "safetyhat": {  # "safetyhat" => 模型名称
                "detect_interval": 1,  # 单位：秒
            },
            "phone": {
                "detect_interval": 1,  # 单位：秒
            },
            "fire": {
                "detect_interval": 1,  # 单位：秒
            },
            "smoking": {
                "detect_interval": 1,  # 单位：秒
            },
            "face": {
                "detect_interval": 1,  # 单位：秒
                "face_feature_config": {
                    "face_path": './facenet/features.csv',  # 人脸的特征文件存储路径
                    # "type": "white",                      # type是white 代表的是白名单
                    "type": "black"
                }
            }
        }
    },
}
```



# main.py文件



## 处理检测结果 handle_detections

下面是一个处理检测结果的函数 `handle_detections`，根据检测结果对图像进行标注和保存，并将结果信息保存到字典 `detection_info` 中，进行打印输出和post至前后端。其中out_ip是前后端指定的可以点链接直接打开的地址，后面加上文件名就可以直接打开。

```

out_ip = 'http://192.168.0.203:8000/static/images/'
def handle_detections(frame, detections, names, output_folder, camera_name, model_name, result):
    # 创建输出文件夹
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # 保存检测到的对象的信息
    detection_info = {}
    if model_name in camera_config.camera_config[camera_name]["models"] and result:  
        now_time = time.strftime('%Y%m%d_%H%M%S')  # 获取当前的时间戳，并遍历检测结果 detections，其中每个结果由图像 im 和检测信息 det 组成
        for _, (im, det) in enumerate(detections):
            if len(det):
                for cls, xyxy, conf in det:
                    if model_name == "face":  #如果是人脸检测模型 "face"，首先检查是否有人脸特征的配置信息
                        face_config = camera_config.camera_configs[camera_name]["models"]["face"]
                        if "face_feature_config" in face_config:
                            face_feature_config = face_config["face_feature_config"]
                            face_path = face_feature_config.get("face_path")  #获取人脸特征文件的路径
                            face_type = face_feature_config.get("type")
                            face_feature_known_list = get_face_database(face_path)  #获取人脸特征数据库
                            face_feature = get_face_descriptor(im, [int(xyxy[0]), int(xyxy[1]), int(xyxy[2]), int(xyxy[3])])  #获取当前检测到的人脸特征
                            name = return_name(face_feature,face_feature_known_list)  #调用 return_name 函数检测人脸是否属于白名单或黑名单中的人脸，并根据检测结果进行标注
                            label = f'{names[int(cls)]} {conf:.2f}'
                            if name != config.yolo_model_configs[model_name]["event"]:
                                if face_type == "black":
                                    plot_one_box(xyxy, im, label=name, color=(
                                        0, 0, 255), line_thickness=2)
                                if face_type == "white":
                                    plot_one_box(xyxy, im, label=name, color=(
                                        255, 0, 0), line_thickness=2)
                                detection_info = {
                                    'camera_name': camera_name,
                                    'model_name': model_name,
                                    'detection_time': now_time,
                                    'result': name,
                                    'image_save_path': '',
                                }
                            else:
                                plot_one_box(xyxy, im, label=label, color=(
                                    0, 255, 0), line_thickness=2)

                    else:  #对于其他模型，直接进行标注
                        label = f'{names[int(cls)]} {conf:.2f}'
                        if label == config.yolo_model_configs[model_name]["event"]:
                            plot_one_box(xyxy, im, label=label, color=(
                                0, 0, 255), line_thickness=2)
                        else:
                            plot_one_box(xyxy, im, label=label, color=(
                                0, 255, 0), line_thickness=2)
                        detection_info = {
                            'camera_name': camera_name,
                            'model_name': model_name,
                            'detection_time': now_time,
                            'result': result,
                            'image_save_path': '',
                            # 'confidence': f'{conf:.2f}',
                            # 'bbox': [int(x) for x in xyxy]

                        }
        # 保存检测结果为图片,检测到了再保存，图片路径由摄像头名称、模型名称和时间戳组成
        output_path = os.path.join(
            output_folder, f"{camera_name}_{model_name}_{now_time}.jpg")
        if detection_info:
            cv2.imwrite(output_path, im)
            out_ips = out_ip + \
                f"{camera_name}_{model_name}_{now_time}.jpg"
            detection_info['image_save_path'] = out_ips

            # inserter.insert_data(TABLE_NAME, detection_info)
            response = requests.post(url, json=detection_info)
            if response.status_code == 200:
                print("success")
    print(model_name + "检测结果")
    print(detection_info)
```



## 旋转图像

下面是一个旋转图像的函数 `rotate_frame`，根据给定的角度对图像进行旋转。基本不用动，根据camera_cofig就可以实现图像的旋转。

```
def rotate_frame(frame, angle: int):
    """旋转frame角度

    Args:
        frame (_type_): 摄像头帧
        angle (int): 旋转角度，正数为顺时针旋转，负数为逆时针旋转

    Returns:
        _type_: 旋转后的frame
    """
    # 获取图像尺寸
    height, width = frame.shape[:2]

    # 计算旋转中心
    center = (width / 2, height / 2)

    # 使用cv2.getRotationMatrix2D获取旋转矩阵
    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1)

    # 使用cv2.warpAffine应用旋转
    rotated_frame = cv2.warpAffine(frame, rotation_matrix, (width, height))

    #返回旋转后的图像
    return rotated_frame
```



## 摄像头处理以及模型推理

下面是一个处理摄像头以及模型推理的函数 `process_camera`，对摄像头捕获的图像进行处理和检测。其中包括对帧数的处理，然后根据配置文件中的检测间隔取图像传入给模型进行推理，返回结果后再传入handle_detections进行结果的处理以及post。

```
def process_camera(camera_config, RESNET_API_SELECT, YOLO_API_SELECT):
    global global_image_to_show
  
    cap = cv2.VideoCapture(camera_config["url"])  # 打开指定 URL 的摄像头
    fps = cap.get(cv2.CAP_PROP_FPS)    # 获取摄像头的帧率 fps

    print(fps)

    reset_interval_frames = 10 * 60 * fps  # 默认为每10分钟清零
    frame_count = 0    #帧计数器

    last_frame_count = {}    #上一次处理的帧计数
    output_folder = "/home/vision/Desktop/box-python/backend/static/images"  # 输出文件夹

    while True:
        ret, frame = cap.read()

        if not ret:
            break

        #对每一帧，调用 rotate_frame 函数将图像按照摄像头配置的角度进行旋转
        frame = rotate_frame(frame, camera_config["angle"])    

        with global_image_lock:
            global_image_to_show = frame

        frame_count += 1
        if frame_count >= reset_interval_frames:
            frame_count = 0
        for model_name in camera_config["models"]:
            last_frame_count[model_name] = 0
        for model_name, model_conf in camera_config["models"].items():
            detect_interval = model_conf["detect_interval"]
            frames_interval = int(detect_interval * fps)  # 根据摄像头fps换算抽帧间隔

            if model_name in RESNET_API_SELECT and frame_count % frames_interval == 0:
                result = RESNET_API_SELECT[model_name].resnet_dectect(frame)
                resnet_handle_detections(
                    frame, result, output_folder, camera_config['camera_name'], model_name)

            if model_name in YOLO_API_SELECT and frame_count % frames_interval == 0:
               
                detections, names, result = YOLO_API_SELECT[model_name].detect([
                                                                               frame])
             
                # 处理检测结果
                handle_detections(frame, detections, names, output_folder, camera_config['camera_name'],
                                  model_name, result)

                # 显示结果
                last_frame_count[model_name] = frame_count

    cap.release()

```



## 主函数

主函数中包括了将模型的参数读取出来，并加载，也包括了将摄像头的参数读取出来，传入模型进行推理。

```
if __name__ == '__main__':
    
    # yolo模型
    YOLO_API_SELECT = {}    #用于存储加载的 YOLO 模型和对应的检测 API
    yolo_model_configs = config.yolo_model_configs
    # model_url= ""  					#获取最新模型参数的地址
    # yolo_model_configs = get_model_config(model_url)
    for model_name, conf in yolo_model_configs.items():
        opt = Option(**conf)
        model = load_model(opt)
        print(model_name + "模型加载成功...")
        YOLO_API_SELECT[model_name] = DetectAPI(
            opt=opt, model=model, model_name=model_name)

    # resnet模型（效果不好，暂时模型中不包括）
    RESNET_API_SELECT = {}
    resnet_model_configs = config.resnet_model_configs
    for model_name, conf in resnet_model_configs.items():	//遍历模型配置文件
        data_transform, class_indict, device, model = load_models(
            conf["json"], conf["weights"], conf["img_size"])
        print(model_name + "模型加载成功")
        RESNET_API_SELECT[model_name] = ResnetDetectAPI(model=model, data_transform=data_transform,
                                                        class_indict=class_indict, device=device)


    get_camera_config(camera_url)  #更新摄像头的地址
    print(camera_config.camera_config)
    camera_configs=camera_config.camera_config  #获取摄像头的配置信息并存储在 camera_configs 中

    #创建多个线程，每个线程负责处理一个摄像头的图像。调用 process_camera 函数，并传入摄像头的配置信息等
    threads = []
    for cam_name, cam_conf in camera_configs.items():	//遍历摄像头配置文件，并传入模型推理函数
        t = threading.Thread(target=process_camera, args=(
            cam_conf, RESNET_API_SELECT, YOLO_API_SELECT))
        threads.append(t)
        t.start()

    # 在主线程中显示全局图像，当按下键盘上的 ‘q’ 键时退出显示
    while True:
        if global_image_to_show is not None:
            with global_image_lock:
                cv2.imshow('Camera', global_image_to_show)
        if cv2.waitKey(1) == ord('q'):
            break
    cv2.destroyAllWindows()

    for t in threads:
        t.join()

```



# 其他

有问题再补充
